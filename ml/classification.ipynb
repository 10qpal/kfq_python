{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape (10, 1) , t_data.shape (10, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]).reshape(10, 1)\n",
    "t_data = np.array([0, 0, 0, 0,  0,  0,  1,  1,  1,  1]).reshape(10, 1)\n",
    "\n",
    "print(\"x_data.shape\", x_data.shape, \", t_data.shape\", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.82179954]] , W.shape =  (1, 1) , b =  [0.75405794] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(1, 1)\n",
    "b = np.random.rand(1)\n",
    "\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 출력은 y = sigmoid(Wx+b)이며, 손실함수는 cross-entropy로 나타냄\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def loss_func(x, t):\n",
    "    delta = 1e-7 # log 무한대 발산 방지\n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum(t*np.log(y+delta) + (1-t)*np.log((1-y)+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001(미세하게 변하는 x값)\n",
    "    grad = np.zeros_like(x) # x와 같은 모양을 만듦, 값은 모두 0\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite']) # iterator\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index # 위치값을 가져와서 idx에 저장\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x + delta_x)\n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x) # f(x - delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 값 계산 함수\n",
    "# 입력변수 x, t : numpy type\n",
    "def error_val(x, t):\n",
    "    delta = 1e-7 # log 무한대 발산 방지\n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum(t*np.log(y+delta) + (1-t)*np.log((1-y)+delta))\n",
    "\n",
    "# 학습을 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "# 입력변수 x : numpy type\n",
    "def predict(x):\n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y >= 0.5:\n",
    "        result = 1 # True\n",
    "    else:\n",
    "        result = 0 # False\n",
    "    \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  39.1435415109287 , Initial W =  [[0.82179954]] , Initial b =  [0.75405794]\n",
      "step =  0 , error value =  21.566256613346045 , W =  [[0.40500971]] , b =  [0.69736499]\n",
      "step =  500 , error value =  2.262627457926495 , W =  [[0.3426392]] , b =  [-4.6034727]\n",
      "step =  1000 , error value =  1.6314276524076332 , W =  [[0.49499964]] , b =  [-6.19587258]\n",
      "step =  1500 , error value =  1.3873629678754547 , W =  [[0.57797406]] , b =  [-7.29879538]\n",
      "step =  2000 , error value =  1.2355317174040117 , W =  [[0.6436803]] , b =  [-8.16964728]\n",
      "step =  2500 , error value =  1.1285517392131346 , W =  [[0.69897474]] , b =  [-8.90087062]\n",
      "step =  3000 , error value =  1.04743454840226 , W =  [[0.74721213]] , b =  [-9.53764779]\n",
      "step =  3500 , error value =  0.9828797938212699 , W =  [[0.79030502]] , b =  [-10.10570214]\n",
      "step =  4000 , error value =  0.9297159197530458 , W =  [[0.82945593]] , b =  [-10.62118487]\n",
      "step =  4500 , error value =  0.884802389707812 , W =  [[0.86547459]] , b =  [-11.09495628]\n",
      "step =  5000 , error value =  0.8461040939918699 , W =  [[0.89893457]] , b =  [-11.5346993]\n",
      "step =  5500 , error value =  0.8122347375176937 , W =  [[0.93025837]] , b =  [-11.94606626]\n",
      "step =  6000 , error value =  0.7822118224946837 , W =  [[0.95976702]] , b =  [-12.33334724]\n",
      "step =  6500 , error value =  0.7553162244590081 , W =  [[0.98771071]] , b =  [-12.69988219]\n",
      "step =  7000 , error value =  0.7310073279702641 , W =  [[1.01428859]] , b =  [-13.04832682]\n",
      "step =  7500 , error value =  0.708869448102945 , W =  [[1.039662]] , b =  [-13.38083083]\n",
      "step =  8000 , error value =  0.6885767408665874 , W =  [[1.06396364]] , b =  [-13.69916104]\n",
      "step =  8500 , error value =  0.6698694938345713 , W =  [[1.08730415]] , b =  [-14.00478893]\n",
      "step =  9000 , error value =  0.6525376693692124 , W =  [[1.10977677]] , b =  [-14.29895426]\n",
      "step =  9500 , error value =  0.6364092110746802 , W =  [[1.13146095]] , b =  [-14.58271224]\n",
      "step =  10000 , error value =  0.62134156187579 , W =  [[1.15242497]] , b =  [-14.85696919]\n",
      "step =  10500 , error value =  0.6072153983137816 , W =  [[1.17272797]] , b =  [-15.1225099]\n",
      "step =  11000 , error value =  0.5939299259738443 , W =  [[1.19242158]] , b =  [-15.38001889]\n",
      "step =  11500 , error value =  0.581399295029203 , W =  [[1.21155114]] , b =  [-15.63009717]\n",
      "step =  12000 , error value =  0.5695498328983984 , W =  [[1.23015674]] , b =  [-15.87327563]\n",
      "step =  12500 , error value =  0.5583178819794665 , W =  [[1.248274]] , b =  [-16.11002579]\n",
      "step =  13000 , error value =  0.5476480915954547 , W =  [[1.26593471]] , b =  [-16.34076854]\n",
      "step =  13500 , error value =  0.5374920551696902 , W =  [[1.28316741]] , b =  [-16.56588136]\n",
      "step =  14000 , error value =  0.5278072128093512 , W =  [[1.29999782]] , b =  [-16.78570422]\n",
      "step =  14500 , error value =  0.5185559600845656 , W =  [[1.31644918]] , b =  [-17.00054452]\n",
      "step =  15000 , error value =  0.509704918561008 , W =  [[1.33254263]] , b =  [-17.21068126]\n",
      "step =  15500 , error value =  0.5012243343670283 , W =  [[1.34829739]] , b =  [-17.41636853]\n",
      "step =  16000 , error value =  0.49308757895364397 , W =  [[1.36373105]] , b =  [-17.61783846]\n",
      "step =  16500 , error value =  0.4852707320577636 , W =  [[1.37885972]] , b =  [-17.81530378]\n",
      "step =  17000 , error value =  0.477752231269933 , W =  [[1.39369822]] , b =  [-18.00895998]\n",
      "step =  17500 , error value =  0.47051257593538676 , W =  [[1.40826021]] , b =  [-18.19898718]\n",
      "step =  18000 , error value =  0.4635340756607238 , W =  [[1.42255829]] , b =  [-18.38555175]\n",
      "step =  18500 , error value =  0.4568006356599713 , W =  [[1.43660417]] , b =  [-18.56880776]\n",
      "step =  19000 , error value =  0.450297572697672 , W =  [[1.45040868]] , b =  [-18.74889816]\n",
      "step =  19500 , error value =  0.4440114565793824 , W =  [[1.46398191]] , b =  [-18.92595587]\n",
      "step =  20000 , error value =  0.43792997308108683 , W =  [[1.47733327]] , b =  [-19.10010476]\n",
      "step =  20500 , error value =  0.43204180495470496 , W =  [[1.49047153]] , b =  [-19.27146047]\n",
      "step =  21000 , error value =  0.42633652824361185 , W =  [[1.50340491]] , b =  [-19.44013113]\n",
      "step =  21500 , error value =  0.42080452162067694 , W =  [[1.51614111]] , b =  [-19.60621805]\n",
      "step =  22000 , error value =  0.41543688684770547 , W =  [[1.52868734]] , b =  [-19.7698163]\n",
      "step =  22500 , error value =  0.4102253787701821 , W =  [[1.5410504]] , b =  [-19.93101523]\n",
      "step =  23000 , error value =  0.4051623435169707 , W =  [[1.55323669]] , b =  [-20.08989893]\n",
      "step =  23500 , error value =  0.4002406637851048 , W =  [[1.56525222]] , b =  [-20.24654668]\n",
      "step =  24000 , error value =  0.3954537102633944 , W =  [[1.57710269]] , b =  [-20.40103328]\n",
      "step =  24500 , error value =  0.39079529839189064 , W =  [[1.58879348]] , b =  [-20.55342944]\n",
      "step =  25000 , error value =  0.38625964977345084 , W =  [[1.60032967]] , b =  [-20.70380208]\n",
      "step =  25500 , error value =  0.3818413576532548 , W =  [[1.61171609]] , b =  [-20.85221458]\n",
      "step =  26000 , error value =  0.3775353559654412 , W =  [[1.62295732]] , b =  [-20.99872707]\n",
      "step =  26500 , error value =  0.37333689151616245 , W =  [[1.6340577]] , b =  [-21.14339664]\n",
      "step =  27000 , error value =  0.3692414989315549 , W =  [[1.64502135]] , b =  [-21.28627757]\n",
      "step =  27500 , error value =  0.36524497804916856 , W =  [[1.65585223]] , b =  [-21.42742148]\n",
      "step =  28000 , error value =  0.3613433734739646 , W =  [[1.66655406]] , b =  [-21.56687758]\n",
      "step =  28500 , error value =  0.35753295605620344 , W =  [[1.67713042]] , b =  [-21.70469274]\n",
      "step =  29000 , error value =  0.35381020607953867 , W =  [[1.68758472]] , b =  [-21.84091171]\n",
      "step =  29500 , error value =  0.35017179797440334 , W =  [[1.69792021]] , b =  [-21.97557724]\n",
      "step =  30000 , error value =  0.3466145863942384 , W =  [[1.70814002]] , b =  [-22.10873016]\n",
      "step =  30500 , error value =  0.3431355935121876 , W =  [[1.7182471]] , b =  [-22.24040957]\n",
      "step =  31000 , error value =  0.3397319974127055 , W =  [[1.72824433]] , b =  [-22.37065288]\n",
      "step =  31500 , error value =  0.3364011214671393 , W =  [[1.73813443]] , b =  [-22.49949595]\n",
      "step =  32000 , error value =  0.33314042459551346 , W =  [[1.74792002]] , b =  [-22.62697316]\n",
      "step =  32500 , error value =  0.3299474923274547 , W =  [[1.75760362]] , b =  [-22.75311749]\n",
      "step =  33000 , error value =  0.3268200285853125 , W =  [[1.76718764]] , b =  [-22.87796063]\n",
      "step =  33500 , error value =  0.3237558481208982 , W =  [[1.7766744]] , b =  [-23.00153302]\n",
      "step =  34000 , error value =  0.320752869544431 , W =  [[1.78606614]] , b =  [-23.12386392]\n",
      "step =  34500 , error value =  0.3178091088913801 , W =  [[1.79536501]] , b =  [-23.24498149]\n",
      "step =  35000 , error value =  0.3149226736782054 , W =  [[1.80457307]] , b =  [-23.36491285]\n",
      "step =  35500 , error value =  0.31209175740320555 , W =  [[1.81369232]] , b =  [-23.48368411]\n",
      "step =  36000 , error value =  0.30931463445339935 , W =  [[1.82272468]] , b =  [-23.60132044]\n",
      "step =  36500 , error value =  0.30658965538176136 , W =  [[1.83167199]] , b =  [-23.71784612]\n",
      "step =  37000 , error value =  0.303915242523433 , W =  [[1.84053605]] , b =  [-23.83328456]\n",
      "step =  37500 , error value =  0.30128988592189604 , W =  [[1.84931859]] , b =  [-23.94765838]\n",
      "step =  38000 , error value =  0.2987121395394909 , W =  [[1.85802126]] , b =  [-24.06098942]\n",
      "step =  38500 , error value =  0.29618061772871884 , W =  [[1.86664569]] , b =  [-24.17329879]\n",
      "step =  39000 , error value =  0.29369399194314466 , W =  [[1.87519343]] , b =  [-24.28460689]\n",
      "step =  39500 , error value =  0.2912509876687577 , W =  [[1.88366599]] , b =  [-24.39493346]\n",
      "step =  40000 , error value =  0.2888503815582584 , W =  [[1.89206482]] , b =  [-24.50429762]\n",
      "step =  40500 , error value =  0.28649099875250666 , W =  [[1.90039135]] , b =  [-24.61271785]\n",
      "step =  41000 , error value =  0.28417171037450173 , W =  [[1.90864693]] , b =  [-24.72021207]\n",
      "step =  41500 , error value =  0.28189143118300175 , W =  [[1.91683289]] , b =  [-24.82679764]\n",
      "step =  42000 , error value =  0.2796491173735699 , W =  [[1.92495053]] , b =  [-24.9324914]\n",
      "step =  42500 , error value =  0.2774437645161419 , W =  [[1.93300108]] , b =  [-25.03730965]\n",
      "step =  43000 , error value =  0.27527440561906436 , W =  [[1.94098576]] , b =  [-25.14126825]\n",
      "step =  43500 , error value =  0.27314010931052385 , W =  [[1.94890574]] , b =  [-25.24438255]\n",
      "step =  44000 , error value =  0.2710399781288184 , W =  [[1.95676217]] , b =  [-25.34666748]\n",
      "step =  44500 , error value =  0.26897314691372937 , W =  [[1.96455614]] , b =  [-25.44813753]\n",
      "step =  45000 , error value =  0.2669387812921418 , W =  [[1.97228874]] , b =  [-25.54880679]\n",
      "step =  45500 , error value =  0.2649360762510707 , W =  [[1.97996101]] , b =  [-25.64868893]\n",
      "step =  46000 , error value =  0.2629642547923352 , W =  [[1.98757397]] , b =  [-25.74779728]\n",
      "step =  46500 , error value =  0.2610225666632418 , W =  [[1.99512861]] , b =  [-25.84614476]\n",
      "step =  47000 , error value =  0.2591102871581802 , W =  [[2.00262589]] , b =  [-25.94374398]\n",
      "step =  47500 , error value =  0.2572267159865325 , W =  [[2.01006674]] , b =  [-26.04060719]\n",
      "step =  48000 , error value =  0.2553711762024229 , W =  [[2.01745209]] , b =  [-26.13674631]\n",
      "step =  48500 , error value =  0.25354301319230127 , W =  [[2.02478282]] , b =  [-26.23217297]\n",
      "step =  49000 , error value =  0.2517415937168737 , W =  [[2.0320598]] , b =  [-26.32689848]\n",
      "step =  49500 , error value =  0.24996630500350797 , W =  [[2.03928386]] , b =  [-26.42093387]\n",
      "step =  50000 , error value =  0.24821655388642405 , W =  [[2.04645583]] , b =  [-26.51428989]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2 # 발산하는 경우, 1e-3~1e-6 등으로 바꾸어서 실행\n",
    "f = lambda x: loss_func(x_data, t_data)\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \", Initial W = \", W, \", Initial b = \", b)\n",
    "\n",
    "for step in range(50001):\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    if(step%500 == 0): # 결과 출력\n",
    "        print(\"step = \", step, \", error value = \", error_val(x_data, t_data), \", W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.41671871e-09]] 0\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(3)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52239398]] 1\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(13)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
